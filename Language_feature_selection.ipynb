{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#             Notebook #3\n",
    "#                       Join data and perform statistical tests. \n",
    "#\n",
    "\n",
    "#  This Notebook will:\n",
    "#  1. Read session scores from the Affiliation data, LIWC category counts \n",
    "#     Part of Speech frequencies and transitions. \n",
    "#  2. Perform feature selection and do some statistical tests.\n",
    "#  3. Plot some results\n",
    "#\n",
    "#  Caveat Lector: The notebook is structured for our file system structure and input data types. It will\n",
    "#                 require some refactoring to run on other structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#  Imports\n",
    "import os\n",
    "import ssl\n",
    "import io\n",
    "import sys\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn.cross_decomposition import CCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import feature_selection\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.feature_selection import RFECV\n",
    "from statsmodels.stats.multitest import fdrcorrection\n",
    "from sklearn.decomposition import FastICA, PCA\n",
    "\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    " #    Options\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input variables\n",
    "dyadScoresFileName = '/Users/Heisig/Jihan/Results/clinical_scores_dyad.csv'\n",
    "liwcTranscriptFileName = '/Users/Heisig/Jihan/LIWC/LIWC2015_Results_SplitTranscripts.csv'\n",
    "targetFilenames = ['/Users/Heisig/Jihan/Results/target_you_know.csv','/Users/Heisig/Jihan/Results/target_so.csv','/Users/Heisig/Jihan/Results/target_i_said.csv','/Users/Heisig/Jihan/Results/target_you_said.csv']\n",
    "honoreBrunetFileName = '/Users/Heisig/Jihan/Results/honoreBrunetDF.csv'\n",
    "pronounFileName = '/Users/Heisig/Jihan/Results/allPronounDF.csv'\n",
    "ngramFileName = '/Users/Heisig/Jihan/Results/ngramFreqNorms.csv'\n",
    "posTranFileName = '/Users/Heisig/Jihan/Results/allPOStransDF.csv'\n",
    "allEmbeddingFileName = '/Users/Heisig/Jihan/Results/AllEmbeddings.csv'\n",
    "cosInterFileName = '/Users/Heisig/Jihan/Results/interCosDF.csv'\n",
    "cosIndFileName = '/Users/Heisig/Jihan/Results/indCosDF.csv'\n",
    "cosBothFileName = '/Users/Heisig/Jihan/Results/bothCosDF.csv'\n",
    "\n",
    "#Output\n",
    "coerrFileName = '/Users/Heisig/Jihan/Results/coerrCoeffs.csv'\n",
    "liwcDyadFileName = '/Users/Heisig/Jihan/Results/liwcDyadData.csv'\n",
    "metricsFileName = '/Users/Heisig/Jihan/Results/allMetricsPvals.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   import pkg_resources\n",
    "   pkg_resources.get_distribution(\"statsmodels\").version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Functions\n",
    "\n",
    "def plot_coercoeff(ccaDF):\n",
    "  fig = plt.gcf()\n",
    "  fig.set_size_inches(4, 36)\n",
    "  #plt.gcf().subplots_adjust(bottom=0.15)\n",
    "  plt.tight_layout()\n",
    "  sns.set(font_scale=0.8)\n",
    "  g = sns.heatmap(\n",
    "      ccaDF,\n",
    "      xticklabels=ccaDF.columns,\n",
    "      yticklabels=ccaDF.index,\n",
    "      vmin=0,\n",
    "      vmax=1,\n",
    "      cmap=\"YlOrRd\")\n",
    "  g.xaxis.set_label_position('top')\n",
    "  g.xaxis.tick_top() \n",
    "  plt.xticks(rotation=90) \n",
    "  g.set_title(\"CCA Coeff\") \n",
    "  plt.show()\n",
    " \n",
    "\n",
    "def ftestRegressionVariable(analyzeDF,responseVariable):\n",
    "    #Compute an F-Test\n",
    "    print('ftestRegressionVariable analyzeDF.columns: \\n',list(analyzeDF.columns))\n",
    "    model = feature_selection.SelectKBest(score_func=feature_selection.f_regression, k='all')\n",
    "    results = model.fit(analyzeDF, responseVariable)\n",
    "    #print(results.scores_)\n",
    "    #print(results.pvalues_)\n",
    "    localFeatlist = analyzeDF.columns.tolist()\n",
    "    statsDF = pd.DataFrame( list(zip(localFeatlist, results.scores_, results.pvalues_)) ,columns=['feature', 'F-TestScore', 'FT-p-val']) \n",
    "    statsDF.sort_values(by=['FT-p-val'],axis=0,inplace=True)\n",
    "    \n",
    "    #Cutoff features by F-Test P-val\n",
    "    #  Returning all for FDR purposes...\n",
    "    #statsDF = statsDF.loc[statsDF['FT-p-val'] < 0.05]\n",
    "    #Reindex after sort\n",
    "    statsDF  = statsDF.reset_index(drop=True)\n",
    "    #print(statsDF)\n",
    "    \n",
    "    #Return the sorted F-test statistics and their p-value for each feature\n",
    "    return(statsDF)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#   Read the various features and scores into a single dataframe\n",
    "#\n",
    "#   Features:\n",
    "#        LIWC\n",
    "#        Target phrase data (from Jihan POS)\n",
    "#        Pronouns\n",
    "#        POS\n",
    "#        Custom structures\n",
    "\n",
    "#Read Dyad scores\n",
    "dyadDF = pd.read_csv(dyadScoresFileName) \n",
    "\n",
    "print('dyadDF.shape: \\n',dyadDF.shape)\n",
    "#print('dyadDF: \\n',dyadDF)\n",
    "\n",
    "dyadDF.rename(columns = {'Date':'Session'},inplace=True) \n",
    "#dyadDF.drop('Diagnosis', axis=1, inplace=True)\n",
    "dyadDF.drop('Therapist', axis=1, inplace=True)\n",
    "dyadDF.drop('Patient', axis=1, inplace=True)  \n",
    "print('dyadDF.shape: \\n',dyadDF.shape)\n",
    "#print('dyadDF: \\n',dyadDF)\n",
    "dyadCols = dyadDF.columns\n",
    "\n",
    "#Read the embedding file\n",
    "if os.path.isfile(allEmbeddingFileName):\n",
    "   allEmbeddingsDF = pd.read_csv(allEmbeddingFileName)\n",
    "else:\n",
    "   print('Embedding file not found: ', allEmbeddingFileName) \n",
    "\n",
    "#Read Specific target phrase data (from Jihan POS)\n",
    "targetDF = pd.read_csv(targetFilenames[0],sep=',')\n",
    "targetDF.drop(['SentenceList'],axis=1,inplace=True)\n",
    "for targetFilename in targetFilenames[1:]:\n",
    "    target2DF = pd.read_csv(targetFilename,sep=',')\n",
    "    target2DF.drop(['SentenceList'],axis=1,inplace=True)\n",
    "    targetDF = pd.merge(targetDF,target2DF, on=['Speaker','Session'])\n",
    "    print('targetDF.shape: \\n',targetDF.shape)\n",
    "therapistTargetDF = targetDF[targetDF['Speaker']=='therapist'].copy()\n",
    "therapistTargetDF.reset_index(inplace=True,drop=True)\n",
    "print('therapistTargetDF.shape: \\n',therapistTargetDF.shape)\n",
    "patientTargetDF = targetDF[targetDF['Speaker']=='patient'].copy()\n",
    "patientTargetDF.reset_index(inplace=True,drop=True)\n",
    "print('patientTargetDF.shape: \\n',patientTargetDF.shape)\n",
    "\n",
    "#Read Honore Brunet\n",
    "hbDF = pd.read_csv(honoreBrunetFileName,sep=',')\n",
    "print('hbDF.shape: \\n',hbDF.shape)\n",
    "therapistHbDF = hbDF[hbDF['Speaker']=='therapist'].copy()\n",
    "therapistHbDF.reset_index(inplace=True,drop=True)\n",
    "print('therapistHbDF.shape: \\n',therapistHbDF.shape)\n",
    "patientHbDF = hbDF[hbDF['Speaker']=='patient'].copy()\n",
    "patientHbDF.reset_index(inplace=True,drop=True)\n",
    "print('patientHbDF.shape: \\n',patientHbDF.shape)\n",
    "\n",
    "#Read Pronoun features\n",
    "pnDF = pd.read_csv(pronounFileName,sep=',')\n",
    "print('pnDF.shape: \\n',pnDF.shape)\n",
    "therapistPnDF = pnDF[pnDF['Speaker']=='therapist'].copy()\n",
    "therapistPnDF.reset_index(inplace=True,drop=True)\n",
    "print('therapistPnDF.shape: \\n',therapistPnDF.shape)\n",
    "patientPnDF = pnDF[pnDF['Speaker']=='patient'].copy()\n",
    "patientPnDF.reset_index(inplace=True,drop=True)\n",
    "print('patientPnDF.shape: \\n',patientPnDF.shape)\n",
    "\n",
    "#Read POS transition features\n",
    "posDF = pd.read_csv(posTranFileName,sep=',')\n",
    "print('posDF.shape: \\n',posDF.shape)\n",
    "therapistPosDF = posDF[posDF['Speaker']=='therapist'].copy()\n",
    "therapistPosDF.reset_index(inplace=True,drop=True)\n",
    "print('therapistPosDF.shape: \\n',therapistPosDF.shape)\n",
    "patientPosDF = posDF[posDF['Speaker']=='patient'].copy()\n",
    "patientPosDF.reset_index(inplace=True,drop=True)\n",
    "print('patientPosDF.shape: \\n',patientPosDF.shape)\n",
    "\n",
    "#Read ngram features\n",
    "ngramDF = pd.read_csv(ngramFileName,sep=',')\n",
    "print('ngramDF.shape: \\n',ngramDF.shape)\n",
    "therapistNgramDF = ngramDF[ngramDF['Speaker']=='therapist'].copy()\n",
    "therapistNgramDF.reset_index(inplace=True,drop=True)\n",
    "print('therapistNgramDF: \\n',therapistNgramDF)\n",
    "patientNgramDF = ngramDF[ngramDF['Speaker']=='patient'].copy()\n",
    "patientNgramDF.reset_index(inplace=True,drop=True)\n",
    "print('patientNgramDF.shape: \\n',patientNgramDF.shape)\n",
    "\n",
    "\n",
    "#                  Cosine Similarity features\n",
    "\n",
    "#Read Cosine transition features\n",
    "cosInterDF = pd.read_csv(cosInterFileName,sep=',')\n",
    "print('cosInterDF.shape: \\n',cosInterDF.shape)\n",
    "therapistInterCosDF = cosInterDF[cosInterDF['Speaker']=='therapist'].copy()\n",
    "therapistInterCosDF.reset_index(inplace=True,drop=True)\n",
    "print('therapistInterCosDF.shape: \\n',therapistInterCosDF.shape)\n",
    "patientInterCosDF = cosInterDF[cosInterDF['Speaker']=='patient'].copy()\n",
    "patientInterCosDF.reset_index(inplace=True,drop=True)\n",
    "print('patientInterCosDF.shape: \\n',patientInterCosDF.shape)\n",
    "\n",
    "#Read Cosine both features\n",
    "cosBothDF = pd.read_csv(cosBothFileName,sep=',')\n",
    "print('cosBothDF.shape: \\n',cosBothDF.shape)\n",
    "therapistBothDF = cosBothDF[cosBothDF['Speaker']=='therapist'].copy()\n",
    "therapistBothDF.reset_index(inplace=True,drop=True)\n",
    "print('therapistBothDF.shape: \\n',therapistBothDF.shape)\n",
    "patientBothDF = cosBothDF[cosBothDF['Speaker']=='therapist'].copy()\n",
    "patientBothDF.reset_index(inplace=True,drop=True)\n",
    "print('patientBothDF.shape: \\n',patientBothDF.shape)\n",
    "\n",
    "#Read Cosine both transition features\n",
    "posIndDF = pd.read_csv(cosIndFileName,sep=',')\n",
    "print('posIndDF.shape: \\n',posIndDF.shape)\n",
    "therapistIndDF = posIndDF[posIndDF['Speaker']=='therapist'].copy()\n",
    "therapistIndDF.reset_index(inplace=True,drop=True)\n",
    "print('therapistIndDF.shape: \\n',therapistIndDF.shape)\n",
    "patientIndDF = posIndDF[posIndDF['Speaker']=='patient'].copy()\n",
    "patientIndDF.reset_index(inplace=True,drop=True)\n",
    "print('patientIndDF.shape: \\n',patientIndDF.shape)\n",
    "\n",
    "#Read LIWC category percentages\n",
    "liwcDF = pd.read_csv(liwcTranscriptFileName,sep=',')\n",
    "print('liwcDF.shape: \\n',liwcDF.shape)\n",
    "liwcDF.sort_values(by=['Filename'],inplace=True)\n",
    "liwcDF.reset_index(inplace=True,drop=True)\n",
    "#print('liwcDF: \\n',liwcDF)\n",
    "\n",
    "#LIWC fixup and concatenation of other feature DFs\n",
    "patientDF = liwcDF[liwcDF['Filename'].str.contains('patient')].copy()\n",
    "patientDF.reset_index(inplace=True,drop=True)\n",
    "SessionSeriesDF = patientDF['Filename'].str.split('_',1,expand=True)\n",
    "patientDF['Session'] = SessionSeriesDF[0]\n",
    "patientDF.drop('Filename', axis=1, inplace=True)\n",
    "patientDF['Session'] = patientDF['Session'].astype('int64')\n",
    "patientDF = pd.merge(patientDF,patientTargetDF.drop(['Speaker'], axis=1), on='Session')\n",
    "patientDF = pd.merge(patientDF,patientHbDF.drop(['Speaker'], axis=1), on='Session')\n",
    "patientDF = pd.merge(patientDF,patientPnDF.drop(['Speaker'], axis=1), on='Session')\n",
    "patientDF = pd.merge(patientDF,patientPosDF.drop(['Speaker'], axis=1), on='Session')\n",
    "patientDF = pd.merge(patientDF,patientNgramDF.drop(['Speaker'], axis=1), on='Session')\n",
    "patientDF = patientDF.add_prefix('Patient_')\n",
    "patientDF.rename(columns = {'Patient_Session':'Session'},inplace=True)\n",
    "print('patientDF: \\n',patientDF.shape)\n",
    "#print('patientDF: \\n',patientDF.head())\n",
    "\n",
    "therapistDF = liwcDF[liwcDF['Filename'].str.contains('therapist')].copy()\n",
    "therapistDF.reset_index(inplace=True,drop=True)\n",
    "SessionSeriesDF = therapistDF['Filename'].str.split('_',1,expand=True)\n",
    "therapistDF['Session'] = SessionSeriesDF[0]\n",
    "therapistDF.drop('Filename', axis=1, inplace=True)\n",
    "therapistDF['Session'] = therapistDF['Session'].astype('int64')\n",
    "therapistDF = pd.merge(therapistDF,therapistTargetDF.drop(['Speaker'], axis=1), on='Session')\n",
    "therapistDF = pd.merge(therapistDF,therapistHbDF.drop(['Speaker'], axis=1), on='Session')\n",
    "therapistDF = pd.merge(therapistDF,therapistPnDF.drop(['Speaker'], axis=1), on='Session')\n",
    "therapistDF = pd.merge(therapistDF,therapistPosDF.drop(['Speaker'], axis=1), on='Session')\n",
    "therapistDF = pd.merge(therapistDF,therapistNgramDF.drop(['Speaker'], axis=1), on='Session')\n",
    "therapistDF = therapistDF.add_prefix('Therapist_')\n",
    "therapistDF.rename(columns = {'Therapist_Session':'Session'},inplace=True)\n",
    "print('therapistDF.shape: \\n',therapistDF.shape)\n",
    "#print('therapistDF: \\n',therapistDF.head())\n",
    "\n",
    "#Merge the two datasets on session (this needs to be more unique to avoid multiple sessions in a day issues)\n",
    "#Doing this to make sure we are really aligned before splitting into X and Y\n",
    "totalLIWCDF = pd.merge(patientDF,therapistDF, on='Session')\n",
    "totalLIWCDF['Session'] = totalLIWCDF['Session'].astype('int64')\n",
    "print('totalLIWCDF.shape: \\n',totalLIWCDF.shape)\n",
    "#totalLIWCDF = pd.merge(totalLIWCDF,bothDF, on='Session')\n",
    "totalDF = pd.merge(totalLIWCDF, dyadDF, on='Session') \n",
    "\n",
    "totalDF.set_index('Session', inplace = True)\n",
    "print('totalDF: ',totalDF.shape)\n",
    "#print('totalDF: ',totalDF.head())\n",
    "\n",
    "#Update col lists to reflect dropped columns in totalDF\n",
    "dyadCols = list(set(dyadCols) & set(totalDF.columns))\n",
    "#print('dyadCols: ',dyadCols)\n",
    "liwcCols = list(totalLIWCDF.columns)\n",
    "#print('liwcCols: ',liwcCols)\n",
    "totalDF.to_csv(liwcDyadFileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Start with the joined DF created in this NoteBook: Jihan LIWC per Turn and Stanza Testing\n",
    " \n",
    "fileName = liwcDyadFileName\n",
    "#Read joined LIWC, Clinical, and Text data\n",
    "totalDF = pd.read_csv(fileName) \n",
    "print('totalDF.shape: \\n',totalDF.shape)\n",
    "#totalDF.drop('Modality', axis=1, inplace=True)\n",
    "#totalDF.drop('Therapist', axis=1,inplace=True)\n",
    "#totalDF.drop('Patient', axis=1,inplace=True)\n",
    "#totalDF.drop('Diagnosis', axis=1,inplace=True)\n",
    "#totalDF.drop('Speaker', axis=1,inplace=True)\n",
    "#totalDF.drop('Filename', axis=1,inplace=True)\n",
    "#totalDF.drop('Unnamed: 19', axis=1,inplace=True)\n",
    "\n",
    "#Read Dyad scores\n",
    "clinicalDF = pd.read_csv(dyadScoresFileName) \n",
    "print('clinicalDF.shape: \\n',clinicalDF.shape)\n",
    "print('clinicalDF: \\n',clinicalDF)\n",
    "\n",
    "clinicalDF.rename(columns = {'Date':'Session'},inplace=True) \n",
    "#clinicalDF.drop('Diagnosis', axis=1, inplace=True)\n",
    "#clinicalDF.drop('Therapist', axis=1, inplace=True)\n",
    "#clinicalDF.drop('Patient', axis=1, inplace=True)\n",
    "clinicalDF.drop('Session', axis=1, inplace=True)\n",
    "print('clinicalDF.shape: \\n',clinicalDF.shape)\n",
    "print('clinicalDF: \\n',clinicalDF)\n",
    "clinicalCols = clinicalDF.columns\n",
    "clinicalCols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalDF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#                                              Find the first X PCs of the most differentially expressed features \n",
    "components = 5\n",
    "pca = PCA(n_components=components)\n",
    "pca.fit(posDF.drop(['Session','Speaker'], axis=1))\n",
    "#Show explained variance\n",
    "print('PC explained_variance_ratios: \\n',pca.explained_variance_ratio_)\n",
    "print('PC singular_values: \\n',pca.singular_values_) \n",
    "print('PC components: \\n',pca.components_)\n",
    "pcDF = pd.DataFrame(pca.transform(inputFeatureDF),columns=['MIPC1','MIPC2','MIPC3'])\n",
    "finalDF = pd.concat([posDF, pcDF], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Setup variables for CCA\n",
    "liwcCols = ['WC',\n",
    " 'Analytic',\n",
    " 'Clout',\n",
    " 'Authentic',\n",
    " 'Tone',\n",
    " 'WPS',\n",
    " 'Sixltr',\n",
    " 'Dic',\n",
    " 'function',\n",
    " 'pronoun',\n",
    " 'ppron',\n",
    " 'i',\n",
    " 'we',\n",
    " 'you',\n",
    " 'shehe',\n",
    " 'they',\n",
    " 'ipron',\n",
    " 'article',\n",
    " 'prep',\n",
    " 'auxverb',\n",
    " 'adverb',\n",
    " 'conj',\n",
    " 'negate',\n",
    " 'verb',\n",
    " 'adj',\n",
    " 'compare',\n",
    " 'interrog',\n",
    " 'number',\n",
    " 'quant',\n",
    " 'affect',\n",
    " 'posemo',\n",
    " 'negemo',\n",
    " 'anx',\n",
    " 'anger',\n",
    " 'sad',\n",
    " 'social',\n",
    " 'family',\n",
    " 'friend',\n",
    " 'female',\n",
    " 'male',\n",
    " 'cogproc',\n",
    " 'insight',\n",
    " 'cause',\n",
    " 'discrep',\n",
    " 'tentat',\n",
    " 'certain',\n",
    " 'differ',\n",
    " 'percept',\n",
    " 'see',\n",
    " 'hear',\n",
    " 'feel',\n",
    " 'bio',\n",
    " 'body',\n",
    " 'health',\n",
    " 'sexual',\n",
    " 'ingest',\n",
    " 'drives',\n",
    " 'affiliation',\n",
    " 'achieve',\n",
    " 'power',\n",
    " 'reward',\n",
    " 'risk',\n",
    " 'focuspast',\n",
    " 'focuspresent',\n",
    " 'focusfuture',\n",
    " 'relativ',\n",
    " 'motion',\n",
    " 'space',\n",
    " 'time',\n",
    " 'work',\n",
    " 'leisure',\n",
    " 'home',\n",
    " 'money',\n",
    " 'relig',\n",
    " 'death',\n",
    " 'informal',\n",
    " 'swear',\n",
    " 'netspeak',\n",
    " 'assent',\n",
    " 'nonflu',\n",
    " 'filler',\n",
    " 'AllPunc',\n",
    " 'Period',\n",
    " 'Comma',\n",
    " 'Colon',\n",
    " 'SemiC',\n",
    " 'QMark',\n",
    " 'Exclam',\n",
    " 'Dash',\n",
    " 'Quote',\n",
    " 'Apostro',\n",
    " 'Parenth',\n",
    " 'OtherP']\n",
    "\n",
    "diags = set(totalDF['Diagnosis'])\n",
    "diagDict = {k: v for v, k in enumerate(diags)}\n",
    "totalDF.replace({\"Diagnosis\": diagDict},inplace=True)\n",
    "modes = set(totalDF['Modality'])\n",
    "modeDict = {k: v for v, k in enumerate(modes)}\n",
    "totalDF.replace({\"Modality\": modeDict},inplace=True)\n",
    "\n",
    "patientLiwcCols = ['Patient_' + liwcCat for liwcCat in liwcCols]\n",
    "therapistLiwcCols = ['Therapist_' + liwcCat for liwcCat in liwcCols]\n",
    "allLiwcCols = patientLiwcCols+therapistLiwcCols\n",
    "print('allLiwcCols: \\n',allLiwcCols)\n",
    "\n",
    "totalDF.dropna(axis='columns',inplace=True)\n",
    "print('totalDF.shape: ',totalDF.shape)\n",
    "X = totalDF[totalDF.columns.intersection(allLiwcCols)] \n",
    "print('X.shape: ',X.shape)\n",
    "Xcols = list(X.columns)\n",
    "print('X: \\n',X)\n",
    "Y = totalDF[totalDF.columns.intersection(clinicalCols)]\n",
    "print('Y.shape: ',Y.shape)\n",
    "Ycols = list(Y.columns)\n",
    "print('Y: \\n',Y)\n",
    "\n",
    "#Need to scale these things since the variables have different ranges\n",
    "#sc = StandardScaler(with_mean=True, with_std=True)\n",
    "#numpyX = sc.fit_transform(X)\n",
    "#numpyY = sc.fit_transform(Y)\n",
    "\n",
    "#Turn back into dataframes\n",
    "#X = pd.DataFrame(numpyX, columns = Xcols)\n",
    "#Y = pd.DataFrame(numpyY, columns = Ycols)\n",
    "\n",
    "print('X: \\n',X)\n",
    "print('Y: \\n',Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for x in clinicalCols:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalDF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#                Finally ready to try the CCA\n",
    "#components is the reduced number of components to project to\n",
    "components = 2\n",
    "cca = CCA(n_components=components)\n",
    "\n",
    "\n",
    "print('Original data:')\n",
    "print('   X.shape: ',X.shape)\n",
    "print('   Y.shape: ',Y.shape)\n",
    "\n",
    "#Train \n",
    "cca.fit(X, Y)\n",
    "\n",
    "#Projection of original data into reduced dimensions \n",
    "X_red, Y_red = cca.transform(X, Y)\n",
    "print('Reduced dimension data:')\n",
    "print('X_red.shape: ',X_red.shape)\n",
    "print('Y_red.shape: ',Y_red.shape)\n",
    "print('type(X_red): ',type(X_red))\n",
    "reducedXDF = pd.DataFrame(data=X_red,columns=['X1','X2'])\n",
    "reducedYDF = pd.DataFrame(data=Y_red,columns=['Y1','Y2'])\n",
    "reducedDF = pd.concat([reducedXDF, reducedYDF], axis=1)\n",
    "print(reducedDF)\n",
    "\n",
    "#Covariance Matrix\n",
    "print(cca.coef_)\n",
    "coeffDF = pd.DataFrame(cca.coef_,index=X.columns,columns=Y.columns)\n",
    "HTML (coeffDF.to_html())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#                Plot the reduced dimensions\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(8, 8)\n",
    "plt.gcf().subplots_adjust(bottom=0.15)\n",
    "\n",
    "#This is the scatterplot of a distance profile feature vs a raw data feature\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(16, 6)\n",
    "\n",
    "xVar = 'X2'  \n",
    "yVar = 'Y2'\n",
    "        \n",
    "ax = sns.scatterplot(data = reducedDF,\n",
    "                     x=xVar,\n",
    "                     y=yVar,\n",
    "                     alpha=1.0,\n",
    "                     legend='full')\n",
    "ax.legend(loc='upper right', frameon=False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#               Weights, Loadings, Scores\n",
    "#The 'weights' are the correlations for each variable in each component dimension \n",
    "#print('cca.x_weights: \\n',cca.x_weights_)\n",
    "weights_X_DF = pd.DataFrame(data=cca.x_weights_,columns=['cca.x_weights_component_1','cca.x_weights_component_2'],index=list(coeffDF.index))\n",
    "weights_Y_DF = pd.DataFrame(data=cca.y_weights_,columns=['cca.y_weights_component_1','cca.y_weights_component_2'],index=list(coeffDF.columns))\n",
    "weights_X_DF.sort_values(by=['cca.x_weights_component_1'],inplace=True)\n",
    "weights_Y_DF.sort_values(by=['cca.y_weights_component_1'],inplace=True)\n",
    "\n",
    "print(weights_X_DF)\n",
    "print(weights_Y_DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeffDF.sort_values(by=['Patient Alliance'],ascending=False,inplace=True)\n",
    "coeffDF.to_csv(coerrFileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_coercoeff(coeffDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TherapistAllianceStatsDF = ftestRegressionVariable(ftestDF.drop('Therapist Alliance', axis=1),ftestDF['Therapist Alliance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#TherapistAllianceStatsDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AvoidanceStatsDF = ftestRegressionVariable(ftestDF.drop('Avoidance', axis=1),ftestDF['Avoidance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Run an f-test regression against all the clinical variables\n",
    "totalDF.dropna(axis='columns',inplace=True)\n",
    "diags = set(totalDF['Diagnosis'])\n",
    "diagDict = {k: v for v, k in enumerate(diags)}\n",
    "totalDF.replace({\"Diagnosis\": diagDict},inplace=True)\n",
    "modes = set(totalDF['Modality'])\n",
    "modeDict = {k: v for v, k in enumerate(modes)}\n",
    "totalDF.replace({\"Modality\": modeDict},inplace=True)\n",
    "\n",
    "metricsToRegress = ['Patient Alliance', 'Therapist Alliance', 'Total Alliance', 'Alliance Difference', 'Diagnosis', 'Modality', 'Goal', 'Task', 'Bond', 'Closeness', 'Dependence', 'Anxiety', 'Avoidance', 'Number of Visits', 'T_Intrusiveness', 'P_Intrusiveness', 'Age']\n",
    "metricsDF = pd.DataFrame()\n",
    "for metric in metricsToRegress:\n",
    "    print('metric: ',metric)\n",
    "    statsDF = ftestRegressionVariable(totalDF.drop([metric], axis=1),totalDF[metric])\n",
    "    statsDF.insert(0, 'metric', metric)\n",
    "    metricsDF = pd.concat([metricsDF, statsDF], axis=0) \n",
    "metricsDF.reset_index(inplace=True,drop=True)\n",
    "metricsFileName = '/Users/Heisig/Jihan/Results/metricsFtest.csv'\n",
    "metricsDF.to_csv(metricsFileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metricsDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#                               Feature Selection using LASSO\n",
    "#     Setup variables for classification\n",
    "testCols = metricsDF.loc[6:10,'feature']\n",
    "xDF = totalDF[testCols]\n",
    "X = xDF.drop(clinicalCols, axis=1, errors='ignore')\n",
    "print(X.shape)\n",
    "y = totalDF['Patient Alliance']\n",
    "print(len(y))\n",
    "\n",
    "#     Recursive Feature Elimination using Lasso\n",
    "estimator = Lasso(random_state=0,max_iter=10000)\n",
    "selector = RFECV(estimator, step=1, cv=5)\n",
    "selector = selector.fit(X, y)\n",
    "print('selector.support_: ',selector.support_)\n",
    "print('selector.ranking_: ',selector.ranking_)\n",
    "print('selector.score(X,y): ',selector.score(X,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#      Try OLS Regression\n",
    "X2 = sm.add_constant(X)\n",
    "est = sm.OLS(y, X2)\n",
    "est2 = est.fit()\n",
    "print(est2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#                                   #Apply FDR correction \n",
    "\n",
    "targetMetrics = ['Patient Alliance','Therapist Alliance','Total Alliance','Alliance Difference','Diagnosis','Modality','Age','Anxiety','Closeness']\n",
    "#targetMetrics = ['Patient Alliance']\n",
    "#pronounFeatures = ['Therapist_we','Therapist_i','Therapist_shehe','Therapist_you','Therapist_they','Patient_we','Patient_i','Patient_shehe','Patient_you','Patient_they']\n",
    "pronounFeatures = ['Therapist_and_and','Therapist_we','Patient_when_i','Patient_AUX,INTJ','Therapist_pronoun_we','Patient_CCONJ,CCONJ','Therapist_ADP,ADP','Therapist_i',\n",
    "                   'Therapist_okay_okay','Therapist_i_do','Patient_ADV,INTJ','Patient_INTJ,PRON','Therapist_CCONJ,CCONJ',\n",
    "                   'Therapist_i_think','Patient_i','Therapist_yeah_yeah','Therapist_INTJ,SCONJ','Patient_nonflu','Patient_and_and','Patient_PRON,PRON']\n",
    "\n",
    "featureList = pronounFeatures  \n",
    "p_val_cuttoff = 0.05\n",
    "numberOfFeatures = len(featureList)\n",
    "print('numberOfFeatures: ',numberOfFeatures)\n",
    "\n",
    "for targetMetric in targetMetrics:\n",
    "    #Remove metrics from features\n",
    "    fdrDF = metricsDF[metricsDF['feature'].isin(featureList)]\n",
    "    print('fdrDF.shape: ',fdrDF.shape)\n",
    "    #Restrict to features for this metric\n",
    "    fdrDF = fdrDF.loc[fdrDF['metric']==targetMetric]\n",
    "    print('fdrDF.shape: ',fdrDF.shape)\n",
    "    fdrDF.reset_index(inplace=True,drop=True)\n",
    "    \n",
    "    #Do the correction\n",
    "    corrected = fdrcorrection(fdrDF['FT-p-val'], alpha=p_val_cuttoff, method='indep', is_sorted=False)\n",
    "    \n",
    "\n",
    "    allFdrDF = metricsDF[metricsDF['feature'].isin(featureList)]\n",
    "    allFdrDF = allFdrDF.loc[allFdrDF['metric']==targetMetric]\n",
    "    allFdrDF.reset_index(inplace=True,drop=True)\n",
    "    allFdrDF['featureNum'] = allFdrDF.index\n",
    "\n",
    "    fdrDF['Survivor'] = corrected[0]\n",
    "    fdrDF['Corrected-p-val'] = corrected[1]\n",
    "    fdrDF['featureNum'] = fdrDF.index\n",
    "    bonferroni_p_val = p_val_cuttoff/numberOfFeatures\n",
    "    print('bonferroni_p_val: ',bonferroni_p_val)\n",
    "\n",
    "    fdrFileName = '/Users/Heisig/Jihan/Results/fdrCorrectedMetrics_'+targetMetric+'.csv'\n",
    "    fdrDF.to_csv(fdrFileName)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feat in fdrDF.feature:\n",
    "      print(feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_val_cuttoff = 0.05\n",
    "#Remove metrics from features\n",
    "fdrDF = metricsDF.loc[0:55,:].copy()\n",
    "print('fdrDF.shape: ',fdrDF.shape)\n",
    "\n",
    "#Restrict to features for this metric\n",
    "targetMetric = 'Patient Alliance'\n",
    "fdrDF = fdrDF.loc[fdrDF['metric']==targetMetric]\n",
    "print('fdrDF.shape: ',fdrDF.shape)\n",
    "fdrDF.reset_index(inplace=True,drop=True)\n",
    "\n",
    "#Do the correction\n",
    "corrected = fdrcorrection(fdrDF['FT-p-val'], alpha=p_val_cuttoff, method='indep', is_sorted=False)\n",
    "fdrDF['corrected'] = corrected[1]\n",
    "print(corrected)\n",
    "\n",
    "fdrFileName = '/Users/Heisig/Jihan/Results/fdrCorrectedMetrics.csv'\n",
    "fdrDF.to_csv(fdrFileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdrDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "testCols = list(metricsDF.loc[6:34,'feature'])\n",
    "testCols.append('Session')\n",
    "xDF = totalDF[testCols]\n",
    "differentialFeatureFileName = '/Users/Heisig/Jihan/Results/differentialFeatureDF.csv'\n",
    "xDF.to_csv(differentialFeatureFileName, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     Setup variables for classification\n",
    "#X = totalDF.drop(clinicalCols, axis=1, errors='ignore')\n",
    "testCols = metricsDF.loc[6:34,'feature']\n",
    "xDF = totalDF[testCols]\n",
    "X = xDF.drop(clinicalCols, axis=1, errors='ignore')\n",
    "print(X.shape)\n",
    "y = totalDF['Patient Alliance']\n",
    "print(len(y))\n",
    "\n",
    "#Scale\n",
    "scaler = preprocessing.StandardScaler().fit(X)\n",
    "X_scaled = scaler.transform(X)\n",
    "\n",
    "#  Try a linear model to predict \n",
    "model_l = linear_model.LassoLarsCV(normalize= True)\n",
    "cv = LeaveOneOut()\n",
    "scores = cross_val_score(model_l, X_scaled, y, scoring='explained_variance', cv=cv, n_jobs=-1)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testCols = metricsDF.loc[6:34,'feature']\n",
    "xDF = totalDF[testCols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try 5 fold LASSO\n",
    "reg = LassoCV(cv=5, random_state=0,max_iter=10000).fit(X_scaled, y)\n",
    "#This returns R**2\n",
    "reg.score(X_scaled, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalDF.dropna(axis='columns',inplace=True)\n",
    "totalDF.drop('Unnamed: 0',axis=1,inplace=True, errors='ignore')   \n",
    "dependenceStatsDF = ftestRegressionVariable(totalDF.drop('Dependence', axis=1),totalDF['Dependence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#                            Plot two variables\n",
    "sns.set(style='darkgrid')\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(32, 8)\n",
    "plt.gcf().subplots_adjust(bottom=0.15)\n",
    "\n",
    "\n",
    "ax = sns.scatterplot(data=totalDF,\n",
    "                     #y='Patient_Honore',\n",
    "                     y='Therapist_Honore',\n",
    "                     s=75,\n",
    "                     x='Patient Alliance')\n",
    "\n",
    "#Add the sentence to high similarity sentences\n",
    "#highSimDF = plotDF.loc[plotDF.cosine_similarity>0.45]\n",
    "#for index, row in highSimDF.iterrows():\n",
    "#    y = row['index']\n",
    "#    x = row['cosine_similarity']\n",
    "#    sentence = row['text']\n",
    "#    plt.text(x,y,sentence, horizontalalignment='left', size='medium', color='black', weight='light')\n",
    " \n",
    "#tickLabels = list(plotDF['session'])\n",
    "#tickPositions = list(plotDF['index'])\n",
    "#ax.set_xticks(tickPositions)\n",
    "#ax.set_xticklabels(tickLabels,fontsize='medium')\n",
    "\n",
    "#ax1.set_ylim(0,100)\n",
    "\n",
    "#Demarcate the speakers\n",
    "#for index, row in firstSentenceDF.iterrows():\n",
    "#    ax.axhline(row['index'], ls='--')\n",
    "#    ax.text(min(plotDF['cosine_similarity']), row['index'], str(row['Session'])+'-'+str(row['Patient Alliance'])+'-'+str(row['Diagnosis']))#\n",
    "\n",
    "ax.set_xlabel('Patient Alliance',fontsize='xx-large', weight='demi')\n",
    "ax.set_ylabel('Patient Honore',fontsize='xx-large', weight='demi')\n",
    "#plt.title('Therapeutic Alliance Cohort '+reference,fontsize='xx-large', weight='bold')\n",
    "\n",
    "#The magic setting to get ALL ticks to rotate!!!\n",
    "plt.setp(ax.get_xticklabels(), rotation=30, fontsize='medium');\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
